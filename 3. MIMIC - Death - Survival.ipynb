{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('NeuralFineGray/')\n",
    "sys.path.append('NeuralFineGray/DeepSurvivalMachines/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs = pd.read_csv('data/mimic/labs_first_day_subselection.csv', index_col = [0, 1], header = [0])\n",
    "outcomes = pd.read_csv('data/mimic/outcomes_first_day_subselection.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = True\n",
    "n_iter = 10\n",
    "if test:\n",
    "    outcomes = outcomes.sample(frac = 0.2, random_state = 0).sort_index()\n",
    "    labs = labs[labs.index.get_level_values(0).isin(outcomes.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "competing = False\n",
    "if not(competing):\n",
    "    outcomes.Event = outcomes.Event == 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"random\" # \"random\", \"weekday\", \"weekend\"Split on date - Weekend vs weekdays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == \"weekday\":\n",
    "    # Train only on weekends but test on both\n",
    "    training =  training = outcomes.Day <= 4\n",
    "    results = 'results_subselection/mimic/weekday/'\n",
    "elif mode == \"weekend\":\n",
    "    # Train only on weekends but test on both\n",
    "    training = outcomes.Day > 4\n",
    "    results = 'results_subselection/mimic/weekend/'\n",
    "else:\n",
    "    # Random split\n",
    "    training = pd.Series(outcomes.index.isin(outcomes.sample(frac = 0.8, random_state = 0).index), index = outcomes.index)\n",
    "    results = 'results_subselection/mimic/random/'\n",
    "results += 'survival_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total patients: {}'.format(len(training)))\n",
    "print('Training patients: {}'.format(training.sum()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DeepSurv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [[50, 50, 50]]\n",
    "predictions = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a baseline, we build a DeepSurv on the last carried forward observations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Last Carried Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last = labs.groupby('Patient').ffill().groupby('Patient').last() # No need to impute as all should have a value (due to preprocessing)\n",
    "last.fillna(last.mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = ShiftExperiment.create(model = 'deepsurv', \n",
    "                     hyper_grid = {\"survival_args\": [{\"layers\": l} for l in layers],\n",
    "                        \"lr\" : [1e-3, 1e-4],\n",
    "                        \"batch\": [100, 250]\n",
    "                     }, \n",
    "                     path = results + 'deepsurv_last', \n",
    "                     force = True, save = False, n_iter = n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['last'] = se.train(last, outcomes.Remaining, outcomes.Event, training)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = (~labs.isna()).groupby('Patient').sum() # Compute counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = ShiftExperiment.create(model = 'deepsurv', \n",
    "                    hyper_grid = {\"survival_args\": [{\"layers\": l} for l in layers],\n",
    "                        \"lr\" : [1e-3, 1e-4],\n",
    "                        \"batch\": [100, 250]\n",
    "                    }, \n",
    "                    path = results + 'deepsurv_count', \n",
    "                    force = True, save = False, n_iter = n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['count'] = se.train(pd.concat([last, count.add_prefix('count_')], axis = 1), outcomes.Remaining, outcomes.Event, training)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_grid = {\n",
    "        \"layers\": [2],\n",
    "        \"hidden\": [25, 50],\n",
    " \n",
    "        \"survival_args\": [{\"layers\": l} for l in layers],\n",
    "\n",
    "        \"lr\" : [1e-3, 1e-4],\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Value data only"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace missing data and use time to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_simple, ie_to_simple, ie_since_simple, mask_simple, time_simple, event_simple = process(labs.copy(), outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = ShiftExperiment.create(model = 'joint', \n",
    "                    hyper_grid = hyper_grid,\n",
    "                    path = results + 'lstm_value',\n",
    "                    force = True, save = False, n_iter = n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['lstm_value'] = se.train(cov_simple, time_simple, event_simple, training, ie_to_simple, ie_since_simple, mask_simple)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Values and time and mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_selection = pd.concat([labs.copy(), labs.isna().add_suffix('_mask'), compute(labs, time_since_last).add_suffix('_time')], axis = 1)\n",
    "cov_time, ie_to_time, ie_since_time, mask_time, time_time, event_time = process(labs_selection, outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = ShiftExperiment.create(model = 'joint', \n",
    "                    hyper_grid = hyper_grid,\n",
    "                    path = results + 'lstm_value+time+mask',\n",
    "                    force = True, save = False, n_iter = n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['lstm_value+time+mask'] = se.train(cov_time, time_time, event_time, training, ie_to_time, ie_since_time, mask_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Values resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Resampling\n",
    "labs_resample = labs.copy()\n",
    "labs_resample = labs_resample.set_index(pd.to_datetime(labs_resample.index.get_level_values('Time'), unit = 'D'), append = True) \n",
    "labs_resample = labs_resample.groupby('Patient').resample('1H', level = 2).mean() \n",
    "labs_resample.index = labs_resample.index.map(lambda x: (x[0], (x[1] - datetime.datetime(1970,1,1)).total_seconds() / (3600 * 24)))\n",
    "# Ensure last time step is the same\n",
    "shift = labs_resample.groupby('Patient').apply(lambda x: x.index[-1][1]) - labs.groupby('Patient').apply(lambda x: x.index[-1][1])\n",
    "labs_resample.index = labs_resample.index.map(lambda x: (x[0], (x[1] - shift[x[0]])))\n",
    "\n",
    "cov_resample, ie_to_resample, ie_since_resample, mask_resample, time_resample, event_resample = process(labs_resample, outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = ShiftExperiment.create(model = 'joint', \n",
    "                    hyper_grid = hyper_grid,\n",
    "                    path = results + 'lstm+resampled',\n",
    "                    force = True, save = False, n_iter = n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['lstm+resampled'] = se.train(cov_resample, time_resample, event_resample, training, ie_to_resample, ie_since_resample, mask_resample)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU - D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_grid_gru = hyper_grid.copy()\n",
    "hyper_grid_gru[\"typ\"] = ['GRUD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "se = ShiftExperiment.create(model = 'joint', \n",
    "                     hyper_grid = hyper_grid_gru,\n",
    "                     path = results + 'gru_d+mask',\n",
    "                     force = True, save = False, n_iter = n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['gru_d+mask'] = se.train(cov_simple, time_simple, event_simple, training, ie_to_simple, ie_since_simple, mask_simple)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent ODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_grid_gru[\"typ\"] = ['ODE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = ShiftExperiment.create(model = 'joint', \n",
    "                    hyper_grid = hyper_grid_gru,\n",
    "                    path = results + 'ode+mask',\n",
    "                    force = True, save = False, n_iter = n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['ode+mask'] = se.train(cov_simple, time_simple, event_simple, training, ie_to_simple, ie_since_simple, mask_simple)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_grid_joint = hyper_grid.copy()\n",
    "hyper_grid_joint.update(\n",
    "    {\n",
    "        \"temporal\": [\"single\"], \n",
    "        \"temporal_args\": [{\"layers\": l} for l in layers],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint model on value only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = ShiftExperiment.create(model = 'joint', \n",
    "                    hyper_grid = hyper_grid_joint,\n",
    "                    path = results + 'joint+value',\n",
    "                    force = True, save = False, n_iter = n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['joint+value'] = se.train(cov_simple, time_simple, event_simple, training, ie_to_simple, ie_since_simple, mask_simple)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint model on value, mask and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_mixture = np.full(len(cov_time.columns), False)\n",
    "mask_mixture[:len(labs.columns)] = True\n",
    "\n",
    "hyper_grid_joint['obs_mask'] = [mask_mixture] # Avoids to compute the observational process on the additional dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = ShiftExperiment.create(model = 'joint', \n",
    "                    hyper_grid = hyper_grid_joint,\n",
    "                    path = results + 'joint_value+time+mask',\n",
    "                    force = True, save = False, n_iter = n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['joint_value+time+mask'] = se.train(cov_time, time_time, event_time, training, ie_to_time, ie_since_time, mask_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('survival')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "f1b50223f39b64c0c24545f474e3e7d2d3b4b121fe045100fc03a3926bb649af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
